<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Software Project: WasteWise</title>
    <link rel="stylesheet" href="/reset.css">
    <link rel="stylesheet" href="/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
</head>
<body>
    
        <div id="sidebar-placeholder"></div>
        <div id="overlay"></div>
        <div id="menu-icon">&#9776;</div>
    
    <header id="banner" class="project-header">
        <h1>WasteWise Live Analytics</h1>
        <p class="project-dates">HackOHI/O 10/225/25-10/26/25</p>
    </header>

    <main class="project-page-content">
        <div class="card">
            <h2>Project Overview</h2>
            <div class="two-column-layout">
                <div class="column-text">
                    <h3>About this Project</h3>
                    <p>
                        WasteWise Live Analytics is a full-stack, AI-driven platform built to address the critical environmental problem of methane emissions resulting from improperly sorted landfill waste. We designed and deployed a reliable, low-cost system to provide facilities with real-time item-level metrics necessary for operating modern robotic sorting systems.
                    </p>
                    <p>
                        The development required pivoting from a simplistic TensorFlow Image Classification model (which was insufficient for counting multiple items) to a robust YOLOv8 Instance Segmentation pipeline. This shift allowed the system to perform multi-object counting and obtain the precise geometric data (pixel masks) needed to calculate metrics. We solved critical challenges in data integrity and networking (ngrok tunneling) to deliver a continuously updating dashboard via Firebase.
                    </p>
                    <p>
                        The core benefit is two-fold: providing quantifiable environmental ROI ($\text{kg}$ $\text{CO}_2$ avoided) and enabling proactive process optimization by showing operators the live composition of the waste stream.
                    </p>
                    
                    <h3>Key Features</h3>
                    <ul>
                        <li>Live Item Counting via Instance Segmentation: The system identifies and counts every instance of Plastic, Metal, Organic, and Glass in real-time, providing the core metric for robotic systems.</li>
                        <li>Quantifiable Impact Display: Calculates and displays Estimated CO2 Avoided and Waste Composition by Count, communicating tangible environmental value.</li>
                        <li>Robust Live Data Bridge: Utilizes IP Webcam and ngrok tunneling to feed video from a standard phone camera to the cloud, bridging the gap between local hardware and the remote Colab processing environment.</li>
                        <li>Bias Correction and Failover: Includes a software hack to redistribute organic bias in predictions </li>
                    </ul>

                    <h3>Technologies Used</h3>
                    <ul>
                        <li>Machine Learning: YOLOv8n-seg (Instance Segmentation), PyTorch, MiDaS (Monocular Depth Concept)</li>
                        <li>Backend/Cloud: Google Colab (VM), Firebase Firestore (Live Database), Python (Primary Language), `pyngrok` (Tunneling)</li>
                        <li>Frontend/Web: HTML5, CSS3, JavaScript (ES Modules), Chart.js (Visualization), GitHub Pages (Deployment)</li>
                        <li>Networking/IoT: OpenCV (Frame Processing), IP Webcam (Sensor Source)</li>
                    </ul>
                </div>
                <div class="column-visual">
                    <a href="[link-to-live-demo-or-github]" class="button">View Live Demo (Requires Colab Runner)</a>
                    <h3>Core Logic Snippet (Data Aggregation & Push)</h3>
                    <pre><code># Python code excerpt showing final data aggregation before Firebase commit.
if (time.time() - last_upload_time) >= UPLOAD_INTERVAL_SEC:
    total_items = sum(aggregated_item_counts.values())
    
    if total_items > 0:
        # Calculate impact based on mock mass distribution
        mock_mass_distribution = {cls: count * 0.15 for cls, count in aggregated_item_counts.items()}
        impact = calculate_environmental_impact(mock_mass_distribution)
        
        # Prepare upload data with explicit float casting (solves Firebase serialization bug)
        upload_data = {
            'timestamp': firestore.SERVER_TIMESTAMP,
            'total_items_count': float(total_items), 
            'percent_composition': {
                cls: float((count / total_items) * 100) for cls in aggregated_item_counts
            },
            'environmental_impact': {k: float(v) for k, v in impact.items()},
        } 

        db.collection('live_conveyor_belt_stats').add(upload_data)
        aggregated_item_counts.clear()

</code></pre>
                </div>
            </div>
        </div>
    </main>
    
    <script src="/script.js"></script>
</body>
</html>
