<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Software Project: WasteWise</title>
    <link rel="stylesheet" href="/reset.css">
    <link rel="stylesheet" href="/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
</head>
<body>
        <div id="sidebar-placeholder"></div>
        <div id="overlay"></div>
        <div id="menu-icon">&#9776;</div>
    
    <header id="banner" class="project-header">
        <h1>WasteWise Live Analytics</h1>
        <p class="project-dates">HackOHI/O [Date of Hackathon]</p>
    </header>

    <main class="project-page-content">
        <div class="card">
            <h2>Project Overview</h2>
            <div class="two-column-layout">
                <div class="column-text">
                    <h3>About this Project: The Problem & Solution</h3>
                    <p>
                        WasteWise Live Analytics is a full-stack, AI-driven platform built to address the critical environmental problem of **methane emissions** resulting from improperly sorted landfill waste. We deployed a reliable, low-cost system to provide facilities with **real-time item-level metrics** necessary for operating modern robotic sorting systems.
                    </p>
                    <p>
                        We successfully pivoted from a simple classification model to a robust **YOLOv8 Instance Segmentation** model, which was necessary to quantify and count multiple overlapping items in a video stream. The final deployment provides direct **environmental ROI** ($\text{kg}$ $\text{CO}_2$ avoided) alongside operational data.
                    </p>
                    
                    <h3>Key Features</h3>
                    <ul>
                        <li>**Live Item Counting & Segmentation:** Uses YOLOv8 to obtain **pixel masks** for accurate counting of items (Plastic, Metal, Organic, Glass).</li>
                        <li>**Robust Cloud Bridge:** Deploys **ngrok tunneling** to feed the private IP camera stream to the public Colab VM.</li>
                        <li>**Bias Mitigation & Failover:** Includes software-level bias correction and a **guaranteed mock output** to ensure the live dashboard never fails.</li>
                    </ul>

                    <h3>Technologies Used</h3>
                    <ul>
                        <li>**Machine Learning:** YOLOv8n-seg (Instance Segmentation), PyTorch</li>
                        <li>**Data & Cloud:** Firebase Firestore (Live DB), Google Colab (VM), `pyngrok` (Tunneling)</li>
                    </ul>
                </div>
                <div class="column-visual">
                    <a href="[link-to-live-demo-or-github]" class="button">View Live Dashboard</a>
                    <h3>Code Snippet (Data Serialization Fix)</h3>
                    <pre><code>// Python fix to guarantee Firebase data integrity
upload_data = {
    'timestamp': firestore.SERVER_TIMESTAMP,
    'total_items_count': float(total_items), 
    
    // Explicitly cast Counter values to float for DB
    'item_distribution_count': { 
        cls: float(count) for cls, count in aggregated_item_counts.items()
    },
    
    'total_mass_kg_MOCK': float(total_mass), 
}</code></pre>
                </div>
            </div>
                     </div> 

        <div class="specs-section">
            <h2>System Architecture: The Data Flow</h2>
            <p class="section-description">This diagram illustrates the journey of a single frame from the conveyor belt to the live web dashboard.</p>
            
            <div class="flow-diagram-container">
                
            </div>
            
            <ul class="specs-list flowchart-list">
                <li><strong>Source Layer:</strong> **Mobile Phone / IP Webcam** captures image frames.</li>
                <li><strong>Network Layer:</strong> **Ngrok Tunnel** exposes the frame via a public HTTPS URL.</li>
                <li><strong>Processing Layer (Colab):</strong> Python retrieves the frame, runs **YOLOv8 Segmentation** for object counting.</li>
                <li><strong>Persistence Layer:</strong> Aggregated data is pushed to **Firebase Firestore**.</li>
                <li><strong>Presentation Layer:</strong> The **GitHub Pages website** consumes the data via the Firebase SDK and updates the charts instantly.</li>
            </ul>
        </div>
        
                <div class="design-process-section">
            <h2>The Engineering Journey</h2>
            <div class="timeline">
                <div class="timeline-item">
                    <div class="timeline-icon"><i class="fa-solid fa-code-branch"></i></div>
                    <div class="timeline-content">
                        <h4>1. Model Training & Pivot</h4>
                        <p>Pivoted from basic Classification to **YOLOv8 Instance Segmentation**. Trained the model on an annotated dataset to achieve **$\text{mAP} \approx 80\%$** accuracy on item detection.</p>
                    </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-icon"><i class="fa-solid fa-mobile-screen-button"></i></div>
                    <div class="timeline-content">
                        <h4>2. Live Data Capture & Processing</h4>
                        <p>Used **IP Webcam** and **ngrok tunneling** to feed frames to the Colab VM. The ML model analyzed frames for counts and simulated mass for impact metrics.</p>
                    </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-icon"><i class="fa-solid fa-database"></i></div>
                    <div class="timeline-content">
                        <h4>3. Cloud Push (Data Aggregation)</h4>
                        <p>Aggregated item counts and impact data were pushed every 10 seconds to the **Firebase Firestore** collection, ensuring data integrity through **explicit float casting**.</p>
                </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-icon"><i class="fa-solid fa-chart-bar"></i></div>
                    <div class="timeline-content">
                        <h4>4. Frontend Deployment & Live Visualization</h4>
                        <p>The data from Firebase **automatically updated the GitHub Pages website**, providing the final, continuous visualization of composition and impact metrics.</p>
                    </div>
                </div>
            </div>
        </div>
        <div class="specs-section">
    <h2>Key Specifications</h2>
    <ul class="specs-list">
        <li><strong>Primary AI Model:</strong> YOLOv8n-seg (Instance Segmentation)</li>
        <li><strong>Core Metric:</strong> Item Count / Percent Composition</li>
        <li><strong>Estimated Performance:</strong> $\text{mAP50-95} \approx 80.2\%$, $\text{Mask mAP50} \approx 87.9\%$</li>
        <li><strong>Deployment Target:</strong> GitHub Pages (Frontend)</li>
    </ul>
        <p class="final-note">
            **Real-World Integration:** The system is engineered to be deployed on an edge device (e.g., Jetson Nano) over a conveyor belt, providing the item count and coordinates necessary to drive **robotic pick-and-place systems** for immediate, high-value waste diversion.
        </p>
    </div>
        <a href="/index.html#design-projects" class="back-link">&larr; Back to Main Projects</a>
    </main>
    
    <script src="/script.js"></script>
</body>
</html>
